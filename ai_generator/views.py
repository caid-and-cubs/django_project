from django.shortcuts import render, redirect
from django.http import JsonResponse
from django.contrib import messages
from django.core.files.base import ContentFile
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from django.views.generic import ListView
from django.conf import settings
from .models import GeneratedImage
import os
import time
import json
from PIL import Image
import logging

# Configuration du logging
logger = logging.getLogger(__name__)

# Variables globales pour le pipeline
pipe = None
device = "cpu"  # Default to CPU for Vercel compatibility

def can_generate_ai():
    """V√©rifier si la g√©n√©ration IA est activ√©e et possible"""
    return getattr(settings, 'ENABLE_AI_GENERATION', False)

def initialize_pipeline():
    """Initialiser le pipeline Stable Diffusion"""
    global pipe, device
    
    if not can_generate_ai():
        logger.warning("AI generation is disabled")
        return None
        
    if pipe is None:
        try:
            import torch
            from diffusers import StableDiffusionPipeline
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            model_id = "CompVis/stable-diffusion-v1-4"
            logger.info(f"Initialisation du pipeline Stable Diffusion sur {device}")
            
            if device == "cuda":
                pipe = StableDiffusionPipeline.from_pretrained(
                    model_id, 
                    torch_dtype=torch.float16,
                    safety_checker=None,
                    requires_safety_checker=False
                )
                pipe = pipe.to(device)
                pipe.enable_attention_slicing()
            else:
                pipe = StableDiffusionPipeline.from_pretrained(
                    model_id,
                    safety_checker=None,
                    requires_safety_checker=False
                )
                pipe = pipe.to(device)
            
            logger.info("Pipeline initialis√© avec succ√®s")
        except Exception as e:
            logger.error(f"Erreur lors de l'initialisation du pipeline: {str(e)}")
            pipe = None
    return pipe

def create_demo_image(prompt):
    """Cr√©er une image de d√©monstration quand l'IA n'est pas disponible"""
    from PIL import Image, ImageDraw, ImageFont
    import io
    
    # Cr√©er une image de d√©monstration
    img = Image.new('RGB', (512, 512), color='#f8f9fa')
    draw = ImageDraw.Draw(img)
    
    # Ajouter du texte
    try:
        # Essayer de charger une police
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 24)
    except:
        font = ImageFont.load_default()
    
    # Texte centr√©
    text_lines = [
        "üé® Mode D√©monstration",
        "",
        "Prompt:",
        f'"{prompt[:50]}{"..." if len(prompt) > 50 else ""}"',
        "",
        "L'IA n'est pas disponible",
        "sur cette instance"
    ]
    
    y_offset = 150
    for line in text_lines:
        bbox = draw.textbbox((0, 0), line, font=font)
        text_width = bbox[2] - bbox[0]
        x = (512 - text_width) // 2
        draw.text((x, y_offset), line, fill='#6c757d', font=font)
        y_offset += 35
    
    # Sauvegarder en bytes
    img_io = io.BytesIO()
    img.save(img_io, format='PNG')
    img_io.seek(0)
    
    return img_io

def home(request):
    """Vue principale avec le formulaire de g√©n√©ration"""
    recent_images = GeneratedImage.objects.all()[:6]
    return render(request, 'ai_generator/home.html', {
        'recent_images': recent_images,
        'device': device,
        'cuda_available': False,  # Always False on Vercel
        'ai_enabled': can_generate_ai(),
    })

@csrf_exempt
def generate_image(request):
    """API pour g√©n√©rer une image √† partir d'un prompt"""
    if request.method != 'POST':
        return JsonResponse({'error': 'M√©thode non autoris√©e'}, status=405)
    
    try:
        # R√©cup√©rer le prompt
        data = json.loads(request.body)
        prompt = data.get('prompt', '').strip()
        
        if not prompt:
            return JsonResponse({'error': 'Le prompt ne peut pas √™tre vide'}, status=400)
        
        if len(prompt) > 500:
            return JsonResponse({'error': 'Le prompt ne peut pas d√©passer 500 caract√®res'}, status=400)
        
        start_time = time.time()
        logger.info(f"G√©n√©ration d'image pour le prompt: {prompt}")
        
        if can_generate_ai():
            # G√©n√©rer avec l'IA
            pipeline = initialize_pipeline()
            if pipeline is None:
                return JsonResponse({'error': 'Erreur lors de l\'initialisation du mod√®le'}, status=500)
            
            import torch
            with torch.no_grad():
                generator = torch.Generator(device=device).manual_seed(42)
                
                image = pipeline(
                    prompt,
                    num_inference_steps=20,
                    guidance_scale=7.5,
                    generator=generator,
                    height=512,
                    width=512
                ).images[0]
            
            # Sauvegarder l'image
            img_io = io.BytesIO()
            image.save(img_io, format='PNG', quality=95)
            img_io.seek(0)
        else:
            # Mode d√©monstration
            img_io = create_demo_image(prompt)
        
        generation_time = time.time() - start_time
        logger.info(f"Image g√©n√©r√©e en {generation_time:.2f} secondes")
        
        # Cr√©er le nom du fichier
        import uuid
        filename = f"generated_{uuid.uuid4().hex[:8]}.png"
        
        # Sauvegarder en base de donn√©es
        generated_image = GeneratedImage(
            prompt=prompt,
            generation_time=generation_time
        )
        generated_image.image.save(
            filename,
            ContentFile(img_io.getvalue()),
            save=True
        )
        
        return JsonResponse({
            'success': True,
            'image_url': generated_image.image.url,
            'generation_time': round(generation_time, 2),
            'prompt': prompt,
            'demo_mode': not can_generate_ai()
        })
        
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration: {str(e)}")
        return JsonResponse({'error': f'Erreur lors de la g√©n√©ration: {str(e)}'}, status=500)

class ImageGalleryView(ListView):
    """Vue pour afficher la galerie des images g√©n√©r√©es"""
    model = GeneratedImage
    template_name = 'ai_generator/gallery.html'
    context_object_name = 'images'
    paginate_by = 12
    
    def get_queryset(self):
        return GeneratedImage.objects.all().order_by('-created_at')
    
    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        context['ai_enabled'] = can_generate_ai()
        return context

def about(request):
    """Vue √† propos"""
    return render(request, 'ai_generator/about.html', {
        'ai_enabled': can_generate_ai()
    })
